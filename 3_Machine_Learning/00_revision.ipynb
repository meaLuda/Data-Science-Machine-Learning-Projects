{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision\n",
    "\n",
    "## ~ Covers most Machine Learning Notes in this folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:green; align-items:center;'>Machine Learning Basic Processes Template:</h1>\n",
    "<h3 style='color:skyblue'> Notes by: Munyala Eliud</h3>\n",
    "\n",
    "* KEY: BUSINESS UNDERSTANDING\n",
    "\n",
    "~ Before any project involving data ensure there is a clear understanding on the \n",
    "    `WHY`  of the project and the end results you want to achieve\n",
    "\n",
    "* ``LOAD DATA``\n",
    "* ``EDA (explore, clean,visualize, feature_selection,preprocessing,scalling ): case to case basis``\n",
    "\n",
    "> ``Before making any actual predictions,its always a good practice to scale the features so that all of them can be uniformly evaluated.``\n",
    "\n",
    "\n",
    "* ``Data Train test validate split``\n",
    "* ``Instanciate you ML model i.e ``gmodel = GaussianNB`` ``\n",
    "* ``Train by fitting train values to the model i.e ``model = gmodel.fit(X_train, y_train)`` `` \n",
    "* ``Make a model prediction using splite test values i.e ``predicted = model.predict(X_test)`` ``\n",
    "* ``Evaluating the Algorithm``\n",
    "> ---\n",
    "``For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics.`` \n",
    "``The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics i.e`` \n",
    "\n",
    "```\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "> ---\n",
    "\n",
    "*  ``Make further test pred. using outside values/data i.e ``\n",
    "```python \n",
    "new_observation = [[ 10,  3,  4,  0.4]]   \n",
    "new_prediction = model.predict(new_observation) \n",
    "``` \n",
    "* ``Reviewing the solution -- informed after Evaluating the algorithm``\n",
    "\n",
    "* ``Challenging the solution``\n",
    "\n",
    "> ```You should never allow those results to hold the day. You should always be thinking of ways to challenge the results, especially if those results comport with your prior expectation.```\n",
    "\n",
    "*  ``Follow up questions:``\n",
    "1. Did we have the right data?\n",
    "2. Do we need other data to answer our question?\n",
    "3. Did we have the right question?\n",
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Poject Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for naive_bayes classification\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/luda/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will download and import nlkt which is a tokenizer. \n",
    "# This library will help us break (messages) into individual linguistic units i.e. words.\n",
    "#\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  word stemming. \n",
    "# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n",
    "# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n",
    "# \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Naive Bayes\n",
    "\n",
    "### Notes:\n",
    "\n",
    "\n",
    "Naive bayes:\n",
    "<ol>\n",
    "<li>This type of classifier makes the assumption of normal distribution</li>\n",
    "<li>best used in cases when all our features are continuous.</li>\n",
    "</ol>\n",
    "\n",
    "<!-- ### Resources links:\n",
    "*\n",
    "*\n",
    "* -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Project Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Challenge 1\n",
    "---\n",
    "* Question: ``Build a model to determine whether a mushroom is edible.``\n",
    "---\n",
    "* Dataset ``url = http://bit.ly/MushroomDataset``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Challenge 2\n",
    "* ---\n",
    "* Question: ``Given the following two datasets, build a model to determine whether a passenger survived or not.``\n",
    "* ---\n",
    "* Train Dataset ``url = http://bit.ly/TitanicDatasetTrain``\n",
    "* Test Dataset ``url = http://bit.ly/TitanicDatasetTest``\n",
    "* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Challenge 3\n",
    "* ---\n",
    "* Question: ``Build a model to classify a type of glass given the following dataset.``\n",
    "* ---\n",
    "* Dataset ``url = http://bit.ly/GlassDatasetB``\n",
    "* Dataset info:\n",
    "* Type of glass: (class) \n",
    "* -) 1 window glass (from vehicle or building) \n",
    "* -) 2 not window glass (containers, tableware, or headlamps)\n",
    "* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e6cad420e4398edbb7ba2374d625154d5929472e7c7049b665a8784c474571"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
