{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Paths in a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for naive_bayes classification\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will download and import nlkt which is a tokenizer. \n",
    "# This library will help us break (messages) into individual linguistic units i.e. words.\n",
    "#\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  word stemming. \n",
    "# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n",
    "# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n",
    "# \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:yellow'>Machine Learning Basic Processes Template:</h1>\n",
    "<h3 style='color:skyblue'> Notes by: Munyala Eliud</h3>\n",
    "\n",
    "\n",
    "* ``LOAD DATA``\n",
    "* ``EDA (explore, clean,visualize, feature_selection,preprocessing,scalling ): case to case basis``\n",
    "\n",
    "> ``Before making any actual predictions,its always a good practice to scale the features so that all of them can be uniformly evaluated.``\n",
    "\n",
    "\n",
    "* ``Data Train test validate split``\n",
    "* ``Instanciate you ML model i.e ``gmodel = GaussianNB`` ``\n",
    "* ``Train by fitting train values to the model i.e ``model = gmodel.fit(X_train, y_train)`` `` \n",
    "* ``Make a model prediction using splite test values i.e ``predicted = model.predict(X_test)`` ``\n",
    "* ``Evaluating the Algorithm``\n",
    "> ---\n",
    "``For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics.`` \n",
    "``The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics i.e`` \n",
    "\n",
    "```\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "> ---\n",
    "\n",
    "*  ``Make further test pred. using outside values/data i.e ``\n",
    "```python \n",
    "new_observation = [[ 10,  3,  4,  0.4]]   \n",
    "new_prediction = model.predict(new_observation) \n",
    "``` \n",
    "* ``Reviewing the solution -- informed after Evaluating the algorithm``\n",
    "\n",
    "* ``Challenging the solution``\n",
    "\n",
    "> ```You should never allow those results to hold the day. You should always be thinking of ways to challenge the results, especially if those results comport with your prior expectation.```\n",
    "\n",
    "*  ``Follow up questions:``\n",
    "1. Did we have the right data?\n",
    "2. Do we need other data to answer our question?\n",
    "3. Did we have the right question?\n",
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n",
    "\n",
    "### Notes:\n",
    "<p>\n",
    "Naive bayes:\n",
    "<ol>\n",
    "<li>This type of classifier makes the assumption of normal distribution</li>\n",
    "<li>best used in cases when all our features are continuous.</li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "### Resources links:\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Challenge 1\n",
    "* ---\n",
    "* Question: ``Build a model to determine whether a mushroom is edible.``\n",
    "* ---\n",
    "* Dataset ``url = http://bit.ly/MushroomDataset``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2\n",
    "* ---\n",
    "* Question: ``Given the following two datasets, build a model to determine whether a passenger survived or not.``\n",
    "* ---\n",
    "* Train Dataset ``url = http://bit.ly/TitanicDatasetTrain``\n",
    "* Test Dataset ``url = http://bit.ly/TitanicDatasetTest``\n",
    "* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3\n",
    "* ---\n",
    "* Question: ``Build a model to classify a type of glass given the following dataset.``\n",
    "* ---\n",
    "* Dataset ``url = http://bit.ly/GlassDatasetB``\n",
    "* Dataset info:\n",
    "* Type of glass: (class) \n",
    "* -) 1 window glass (from vehicle or building) \n",
    "* -) 2 not window glass (containers, tableware, or headlamps)\n",
    "* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4\n",
    "* ---\n",
    "* Question: ``Build a classifier to help determine whether future patients do or do not have heart disease.``\n",
    "* ---\n",
    "* Dataset ``url = http://bit.ly/HeartDatasetNB``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "### Notes:\n",
    "<p>\n",
    "#:\n",
    "<ol>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "### Resources links:\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "### Notes:\n",
    "<p>\n",
    "#:\n",
    "<ol>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "### Resources links:\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "### Notes:\n",
    "<p>\n",
    "#:\n",
    "<ol>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "### Resources links:\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "### Notes:\n",
    "<p>\n",
    "#:\n",
    "<ol>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "### Resources links:\n",
    "*\n",
    "*\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e6cad420e4398edbb7ba2374d625154d5929472e7c7049b665a8784c474571"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ds_ml_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
