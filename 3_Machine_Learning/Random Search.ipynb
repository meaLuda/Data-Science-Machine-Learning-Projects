{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Python Programming: Random Search","provenance":[{"file_id":"1vwFO9hHu5MKii_kWtnaiU05yrqI4Bypt","timestamp":1634034888223}],"collapsed_sections":["k6mu0__7OjF8","LoZYTKzdNPw1"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X5ma2Mw6_6Dt"},"source":["# Python Programming: Random Search"]},{"cell_type":"markdown","metadata":{"id":"k6mu0__7OjF8"},"source":["## Example"]},{"cell_type":"code","metadata":{"id":"tftAsaCN_xbw"},"source":["## Example 1\n","# ---\n","# Perform hyperparameter tuning then predict the quality of wine using Random Search. \n","# ---\n","# Dataset url = http://bit.ly/TuningDataset\n","# ---\n","# OUR CODE GOES BELOW "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnvF1TbuBFSP"},"source":["# Importing the required libraries\n","# ---\n","#\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6io-7e6WAaLU"},"source":["# Importing our Dataset\n","# ---\n","#\n","dataset = pd.read_csv(\"http://bit.ly/TuningDataset\", sep=';')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fprG-77uCN81"},"source":["# Previewing our Dataset\n","# ---\n","#\n","dataset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85-ZhbKfCQNu"},"source":["# Performing Data Preprocessing\n","# ---\n","# \n","X = dataset.iloc[:, 0:11].values\n","y = dataset.iloc[:, 11].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRYfL5brDIMI"},"source":["# Performing Data Preprocessing\n","# ---\n","# \n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfNu9GniC6TL"},"source":["# Scaling our Data\n","# ---\n","# \n","from sklearn.preprocessing import StandardScaler\n","feature_scaler = StandardScaler()\n","X_train = feature_scaler.fit_transform(X_train)\n","X_test = feature_scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQbqNGppIwCD"},"source":["# Training and Cross Validation\n","# ---\n","# \n","from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(n_estimators=300, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQz-BvHSJD1C"},"source":["# Training and Cross Validation\n","# ---\n","# Next, to implement cross validation, the cross_val_score method \n","# of the sklearn.model_selection library can be used. \n","# The cross_val_score returns the accuracy for all the folds. \n","# Values for 4 parameters are required to be passed to the cross_val_score class. \n","# The first parameter is estimator which basically specifies \n","# the algorithm that you want to use for cross validation. \n","# The second and third parameters, X and y, contain the X_train and y_train data i.e. features and labels. \n","# Finally the number of folds is passed to the cv parameter as shown in the following code\n","# ---\n","# \n","from sklearn.model_selection import cross_val_score\n","all_accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g288wwhYJEcS"},"source":["# Printing the accuracies returned for five folds \n","# by the cross_val_score method by calling print on all_accuracies\n","# ---\n","#\n","print(all_accuracies.mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWXSIEBADSaw"},"source":["# Step 1: Hyperparameters: Getting Started with Random Search\n","# ---\n","# Random search differs from grid search in that we longer \n","# provide a discrete set of values to explore for each hyperparameter; rather, \n","# we provide a statistical distribution for each hyperparameter \n","# from which values may be randomly sampled.\n","# We'll define a sampling distribution for each hyperparameter.\n","# ---\n","# \n","\n","# specify parameters and distributions to sample from\n","from scipy.stats import randint as sp_randint\n","param_dist = {\"max_depth\": [3, None],\n","              \"max_features\": sp_randint(1, 11),\n","              \"min_samples_split\": sp_randint(2, 11),\n","              \"bootstrap\": [True, False],\n","              \"criterion\": [\"gini\", \"entropy\"]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1qVq872GqKC"},"source":["# Step 2: Instantiating RandomizedSearchCV object \n","# ---\n","# \n","from sklearn.model_selection import RandomizedSearchCV \n","random_sr = RandomizedSearchCV(classifier, param_dist, cv = 5) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrb1kDfVMu2H"},"source":["# Step 3: Calling the fit method\n","# ---\n","#\n","random_sr.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLPQKoJdHpZm"},"source":["# Step 4: Checking the parameters that return the highest accuracy\n","# ---\n","#\n","best_parameters = random_sr.best_params_\n","print(best_parameters)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YR2Dh4kBJLpI"},"source":["# Finding the obtained accuracy\n","# --\n","# \n","best_result = random_sr.best_score_\n","print(best_result)\n","\n","# Compare this with the "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LoZYTKzdNPw1"},"source":["## <font color=\"green\">Challenges</font>"]},{"cell_type":"code","metadata":{"id":"a2Fn-tSkKeWl"},"source":["## Challenge 1\n","# ---\n","# Question: Implement hyperparameter tuning using random search upon creating a model to classify \n","# incomes of persons given the following dataset.\n","# ---\n","# Dataset url = http://bit.ly/HyperParameterTuningDataset\n","# ---\n","# OUR CODE GOES BELOW\n","#"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyifQX_bOuEm"},"source":["## Challenge 2\n","# ---\n","# Perform hyperparameter tuning by applying Random search to the challenges that you worked on during Week 8.\n","# ---  "],"execution_count":null,"outputs":[]}]}