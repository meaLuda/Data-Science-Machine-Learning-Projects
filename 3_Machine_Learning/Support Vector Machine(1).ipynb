{"cells":[{"cell_type":"markdown","metadata":{"id":"pW_fzqAzwMez"},"source":["<font color=green>To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.</font>"]},{"cell_type":"markdown","metadata":{"id":"G508HvnDaOM4"},"source":["# Python Programming: Support Vector Machine"]},{"cell_type":"markdown","metadata":{"id":"WHnqODG2CPZz"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"r10OQ-sGiKhJ"},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set(font_scale=1.2)\n","# Import Suport Vector Classifier module from svm library. We'll use SVC to model our data\n","from sklearn.svm import SVC,LinearSVC\n","from sklearn.model_selection import train_test_split\n","# Import scikit-learn metrics module for accuracy calculation\n","from sklearn.metrics import  accuracy_score\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"NLtRMAM8fWOI"},"source":["## **Example 1: Recipe Classification**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x10aOaiBHM6t"},"source":["We are going to implement SVM on the example we mentioned in the overview section. As a recap, our aim is to classify a recipe as as either a muffin recipe or  a cupcake recipe. our dataset will comprise of a bunch of muffin and cupcake recipes. Remember that the difference between a muffin and a cupcake is that a muffin has more Flour while a cupcake has more butter and sugar."]},{"cell_type":"markdown","metadata":{"id":"yuOD8zyRjgTc"},"source":["**Load Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMpYhZSQjnah"},"outputs":[],"source":["# Load the data set\n","# Dataset : https://bit.ly/muffins_and_capcakes\n","\n","recipes = pd.read_csv('muffins_and_cupcakes.csv')\n","recipes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5cJhH9lkR23"},"outputs":[],"source":["# We are going to use Flour and Butter as our classifying criteria. So we plot the two columns to see if we can apply svm on them\n","# Plot two ingredients\n","sns.lmplot('Flour', 'Butter', data=recipes, hue='Type',\n","           palette='Set1', fit_reg=False, scatter_kws={\"s\": 70});"]},{"cell_type":"markdown","metadata":{"id":"5FEAUk6kk6_W"},"source":["From the graph we can have two classes, muffins indicated by red dots and cupcakes representated by the blue dots. We can also observe that indeed points that have a high concetration of flour are muffins and conversely, the ones that have a high concentration of butter are cupcakes. Hence we can use svm to train a model that will be able to classify a recipe as either a muffin recipe or a cupcake recipe."]},{"cell_type":"markdown","metadata":{"id":"-6XoifBNlDhD"},"source":["**Fit the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2nUt0jOlKEs"},"outputs":[],"source":["# Specify the input for the model\n","\n","sugar_butter = recipes[['Flour', 'Butter']].as_matrix()\n","# Put a label of either a muffin or not and assign it 0 or 1\n","type_label = np.where(recipes['Type']=='Muffin',0,1)\n","\n","\n","# Fit the model\n","model = SVC(kernel= 'linear')\n","model.fit(sugar_butter,type_label)"]},{"cell_type":"markdown","metadata":{"id":"y2d2K9SymyDW"},"source":["**Results Visualization**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UI01tEyQm53K"},"outputs":[],"source":["# Get the separating hyperplane\n","w = model.coef_[0] #get the first coefficient of our model\n","a = -w[0] / w[1]\n","# Get the x values of our hyperplane. We achieve this by creating a range numbers from the largest number of the butter vlaues and the smallest number of the butter values.  \n","xx = np.linspace(30, 60)\n","yy = a * xx - (model.intercept_[0]) / w[1]\n","\n","# Plot the hyperplane\n","sns.lmplot('Flour', 'Butter', data=recipes, hue='Type', palette='Set1', fit_reg=False, scatter_kws={\"s\": 70})\n","plt.plot(xx, yy, linewidth=2, color='black');\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzg23i5dgMrw"},"outputs":[],"source":["# Plot the parallels to the separating hyperplane that pass through the support vectors\n","b = model.support_vectors_[0]\n","yy_down = a * xx + (b[1] - a * b[0])\n","b = model.support_vectors_[-1]\n","yy_up = a * xx + (b[1] - a * b[0])\n","\n","# Look at the margins and support vectors\n","sns.lmplot('Flour', 'Butter', data=recipes, hue='Type', palette='Set1', fit_reg=False, scatter_kws={\"s\": 70})\n","plt.plot(xx, yy, linewidth=2, color='black')\n","plt.plot(xx, yy_down, 'k--') #'k--' indicates that we want to draw a black dotted line\n","plt.plot(xx, yy_up, 'k--')\n","plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],s=80, facecolors='none');\n"]},{"cell_type":"markdown","metadata":{"id":"VJAcn1BjgsDC"},"source":["**Prediction and Evaluation**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9YteCtvhAqp"},"outputs":[],"source":["# Now that we have created our model let's use it to make some predictions. Remember the output of our model can either be 0 or 1. 0 being a muffin and 1 being a cupcake as we set it in the type_label variable.\n","# Predict if 60 parts flour and 30 parts butter\n","muffin_or_cupcake = model.predict([[60, 30]])\n","muffin_or_cupcake"]},{"cell_type":"markdown","metadata":{"id":"74EKt9mFp26k"},"source":["Our model gave us an output of 0 which means that it correctly predicted a muffin. This is correct because as we stated earlier muffins have a high concentration of floor. For our understanding let's visualize where the point lies graphically\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jp9td36XqdmE"},"outputs":[],"source":["# Plot the point to visually see where the point lies\n","sns.lmplot('Flour', 'Butter', data=recipes, hue='Type', palette='Set1', fit_reg=False, scatter_kws={\"s\": 70})\n","plt.plot(xx, yy, linewidth=2, color='black')\n","plt.plot(60, 30, 'yo', markersize='9');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjxl5HrStLnL"},"outputs":[],"source":["# We can also go an exra mile to create a function that helps us predict when recipe is muffin or cupcake\n","\n","def muffin_or_cupcake(flour, sugar):\n","    if(model.predict([[flour, sugar]]))==0:\n","        print('You\\'re looking at a muffin recipe!')\n","    else:\n","        print('You\\'re looking at a cupcake recipe!')\n","\n","# Predict if 60 parts flour and 30 parts butter\n","muffin_or_cupcake(60, 30)"]},{"cell_type":"markdown","metadata":{"id":"j4qx6fZxuCMS"},"source":["So far we have only looked at how to implement Svm only on linearly separatable data. In the next session we are going to explore advanced SVM where we have situations in which we have high dimension data.\n","\n","**Note**: In most cases you don't need to plot a gragh when you are doing svm especially if you are dealing with higher dimension planes. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTn4dZ-lAGMk"},"source":["## Example 2: Breast Cancer classification\n"," "]},{"cell_type":"markdown","metadata":{"id":"uLiRSfYIHUCA"},"source":["In this example, we are going to use a cancer dataset to build a model that classifies a cancer diagnosis as either  malignant (harmful) or benign (not harmful). The dataset comprises of 30 features."]},{"cell_type":"markdown","metadata":{"id":"6AzKmAeiB8_C"},"source":["**Loading Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Wek6SlmB2xm"},"outputs":[],"source":["# Load data\n","data = pd.read_csv('http://bit.ly/breast_cancer_dataset')\n","\n","# data.head()"]},{"cell_type":"markdown","metadata":{"id":"_7RND1VTDWOM"},"source":["**Data Exploration**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVeR9auHDfFa"},"outputs":[],"source":["# Check for missing values\n","print(data.isnull().sum())\n","\n","# Drop the column that has NaN values\n","Cancer_data = data.dropna(axis='columns')\n","Cancer_data\n"]},{"cell_type":"markdown","metadata":{"id":"F_EWDRQlEKI8"},"source":["**Split the data into train and test sets**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1325,"status":"ok","timestamp":1570506707312,"user":{"displayName":"John Mutavi","photoUrl":"","userId":"04650186972582562429"},"user_tz":-180},"id":"FNNfYasFESLz","outputId":"8c784bbd-9fc5-402c-c91d-1f0a64c9ad54"},"outputs":[{"data":{"text/plain":["(114,)"]},"execution_count":4,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Seperating the target from our data\n"," X = Cancer_data.drop(['diagnosis','id'],axis=1) # We remove diagnosis column since its our target column and id because its not relevant in diagnosis. \n"," y = np.where(Cancer_data['diagnosis']=='M',0,1)\n","\n","#  Split the data into train and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","y_test.shape\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Rn7AIKrQJYwW"},"source":["**Fitting the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"elapsed":2290,"status":"ok","timestamp":1570506711718,"user":{"displayName":"John Mutavi","photoUrl":"","userId":"04650186972582562429"},"user_tz":-180},"id":"k9D_M6s_xmhS","outputId":"3d17b5d2-67ca-4f34-a6cd-37bed6dfd1d7"},"outputs":[{"data":{"text/plain":["array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n","       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n","       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n","       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n","       1, 0, 0, 1])"]},"execution_count":5,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Let's now build the svm model \n","cancer_model = SVC(kernel = 'linear')\n","# Train the model using the training set\n","cancer_model.fit(X_train,y_train)\n","\n","# Predict the response for the test set\n","y_pred = cancer_model.predict(X_test)\n","y_pred"]},{"cell_type":"markdown","metadata":{"id":"eyKZTXOAKegr"},"source":["**Performance and Ecavluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMkRxi9SKlrX"},"outputs":[],"source":["# Now that we have trained our model, let's test how well it can predict the breast cancer of a patient\n","\n","# Checking the accurancy of the model\n","model_accuracy = accuracy_score(y_test,y_pred)\n","model_accuracy\n","\n","# We've gotten a classification rate of 95.61%. This is a pretty good accuracy score \n","\n","# For further evaluation you can also check the confusion matrix\n","confusion_matrix = confusion_matrix(y_test, y_pred)\n","confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"bEI3BlIvNgcq"},"source":["**Conclusion**\n","\n","Unlike the previous example, we did not need to plot a graph but we were able to get some pretty accurate results. One major resaon behind this is that we were dealing with multiple features so it would have been pretty hard to visualize. \n","\n","In the next session we are going to learn how to tune our parameters so as to achieve more desirable results from our svm model"]},{"cell_type":"markdown","metadata":{"id":"ZYBNLP7Lu6Ns"},"source":["## <font color= green>Challenge 1</fonts>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ4RjqafvHF7"},"outputs":[],"source":["# Classify the following dataset as either a yes or no using support vector machine model.\n","# Predict where this point would lie (-5.5561213215518,3.65465321681)\n","# Dataset -----> http://bit.ly/data_p\n","\n","your code goes here"]},{"cell_type":"markdown","metadata":{"id":"hc83oy8nyi-S"},"source":["## <font color= green>Challenge 2</fonts>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRgIaDIVysqj"},"outputs":[],"source":["# Use the Titanic dataset that you used in Logictic regression and classify the passengers as either survived or not survived.\n","# -------\n","#  Dataset url = http://bit.ly/TitanicTrainDataset\n","# ----------\n","Your code goes here"]},{"cell_type":"markdown","metadata":{"id":"5RM_6cLySvpC"},"source":["## <font color= green>Challenge 3</fonts>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTdbwF2CS5Ue"},"outputs":[],"source":["# Use the titanic dataset that you used in Logistic Regression to classify whether a passangers survived or not\n","# -----\n","#  Dataset url -----> http://bit.ly/TitanicTrainDataset \n","# ---------\n","Your code goes here"]},{"cell_type":"markdown","metadata":{"id":"ASLk1HOGXPTQ"},"source":["## <font color= green>Challenge 4</fonts>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cth6UdArXFF6"},"outputs":[],"source":["# Company wants to automate the loan eligibility process based on customer detail provided while filling online application form.\n","# To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers.\n","# Your task is to predict the loan eligibility.\n","# -------\n","# Dataset url ----> http://bit.ly/loan_data"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of Python Programming: Support Vector Machine.ipynb","provenance":[{"file_id":"1G90t5GFyhwhZkBmrWZGW-QM-CFavkefW","timestamp":1634890312473}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
