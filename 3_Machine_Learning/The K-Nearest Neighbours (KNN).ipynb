{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Python Programming: The K-Nearest Neighbours (KNN)","provenance":[{"file_id":"1DsvJjfbpq0vMSHttWL85kDvuJX4jQuqL","timestamp":1635164349299}],"collapsed_sections":["G_2LcNX_2mRp","59Dl6rn42e6J","Gb5PfVC02jGj","v-Jt6Qra2o-_","jGdhSh8a2vIu","nS97eeWtA8h-","ArCcqqQ_6MS1","vwjo3A_6A3Cn"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"875y1bELFxoO"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"r_DcYFR42f0S"},"source":["# Python Programming: The K-Nearest Neighbours (KNN)"]},{"cell_type":"markdown","metadata":{"id":"G_2LcNX_2mRp"},"source":["## Examples"]},{"cell_type":"markdown","metadata":{"id":"59Dl6rn42e6J"},"source":["### Example 1: Classification"]},{"cell_type":"code","metadata":{"id":"LdqYgpqp2aX9"},"source":["# Example \n","# ---\n","# Question: Predict the class to which these plants belong. \n","# There are three classes in the dataset: Iris-setosa, Iris-versicolor and Iris-virginica. \n","# ---\n","# Dataset url = http://bit.ly/DatasetIris\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HM3M559k3zFq"},"source":["# Importing our libraries\n","# ---\n","# \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeL8e6yt3dH3"},"source":["# Loading our dataset\n","# ---\n","# \n","\n","# Assign colum names to the dataset\n","names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n","\n","# Read dataset to pandas dataframe\n","df = pd.read_csv(\"http://bit.ly/DatasetIris\", names = names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SS61mwWP4ZoA"},"source":["# Previewing our datset\n","# ---\n","# \n","dataset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEQV5uym434k"},"source":["# Splitting our dataset into its attributes and labels\n","# ---\n","# The X variable contains the first four columns of the dataset (i.e. attributes) while y contains the labels.\n","# ---\n","# \n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, 4].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0zETLPa5TMB"},"source":["# Train Test Split\n","# ---\n","# To avoid over-fitting, we will divide our dataset into training and test splits, \n","# which gives us a better idea as to how our algorithm performed during the testing phase. \n","# This way our algorithm is tested on un-seen data\n","# ---\n","# \n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuTM-0TB5nQ0"},"source":["# Feature Scaling\n","# ---\n","# Before making any actual predictions, it is always a good practice to scale the features \n","# so that all of them can be uniformly evaluated.\n","# ---\n","# \n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoc1sh56TaS"},"source":["# Training and Predictions\n","# ---\n","# The first step is to import the KNeighborsClassifier class from the sklearn.neighbors library. \n","# In the second line, this class is initialized with one parameter, i.e. n_neigbours. \n","# This is basically the value for the K. There is no ideal value for K and it is selected after testing and evaluation, \n","# however to start out, 5 seems to be the most commonly used value for KNN algorithm.\n","# ---\n","# \n","from sklearn.neighbors import KNeighborsClassifier\n","classifier = KNeighborsClassifier(n_neighbors=5)\n","classifier.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfGGufz76hsw"},"source":["# The final step is to make predictions on our test data\n","# ---\n","# \n","y_pred = classifier.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Np0d1in_6mL1"},"source":["# Evaluating the Algorithm\n","# ---\n","# For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics. \n","# The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics. \n","# ---\n","# \n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gb5PfVC02jGj"},"source":["### Example 2: Regression"]},{"cell_type":"code","metadata":{"id":"mWBQW_Fx2mmL"},"source":["# Example 2\n","# ---\n","# Question: Predict the age of a voter through the use of other variables in the dataset.\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"315lN1sY39o3"},"source":["# First installing pydataset\n","# ---\n","pip install pydataset "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhVn1U094FtZ"},"source":["# Then loading our libraries\n","# \n","from pydataset import data\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kInMF4SO3Bee"},"source":["# Previewing our turnout dataset\n","# ---\n","# \n","df = data(\"turnout\")\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8zzGmGQ4sHk"},"source":["# Determining the size of the dataset\n","# \n","df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dcxaem5P4fKn"},"source":["# Splitting our data\n","# ---\n","# \n","X = df[['age','income','vote']]\n","y = df['educate']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQABF1Kq3Qv2"},"source":["# Training our algorithm\n","# ---\n","# \n","clf = KNeighborsRegressor(11)\n","clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHaOPpYP3Ypf"},"source":["# Making our prediction\n","# ---\n","# \n","y_pred = clf.predict(X_test)\n","print(mean_squared_error(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-Jt6Qra2o-_"},"source":["## <font color=\"green\">Challenge 1</font>"]},{"cell_type":"code","metadata":{"id":"ufHjmjCo2uaH"},"source":["# Challenge 1\n","# ---\n","# Question: Predict the income level based on the individualâ€™s personal information in the given dataset.\n","# ---\n","# Dataset url = http://bit.ly/DatasetAdult\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGdhSh8a2vIu"},"source":["## <font color=\"green\">Challenge 2</font>"]},{"cell_type":"code","metadata":{"id":"Hrld1Xb52zOK"},"source":["# Challenge 2\n","# ---\n","# Question: Using KNN, predict if the client will subscribe a term deposit (variable y).\n","# ---\n","# Dataset url = http://bit.ly/DatasetBank\n","# ---\n","# Dasest info = http://bit.ly/DatasetBankInfo\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nS97eeWtA8h-"},"source":["## <font color=\"green\">Challenge 3</font>"]},{"cell_type":"code","metadata":{"id":"yPXyXyNdBFwh"},"source":["# Challenge 3\n","# ---\n","# Question: Predict if a person will have diabetes or not using the KNN algorithm.\n","# ---\n","# Dataset url = http://bit.ly/DatasetDiabetes\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArCcqqQ_6MS1"},"source":["## <font color=\"green\">Challenge 4</font>"]},{"cell_type":"code","metadata":{"id":"fSPxkZTH6TKI"},"source":["# Challenge 4\n","# ---\n","# Question: Predict the miles per gallon (mpg) of a car, given its displacement and horsepower.\n","# ---\n","# Dataset Train url = http://bit.ly/AutoMPGTrainDataset\n","# Dataset Test url = http://bit.ly/AutoMPGTestDataset \n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwjo3A_6A3Cn"},"source":["## <font color=\"green\">Challenge 5</font>"]},{"cell_type":"code","metadata":{"id":"_2yQMQysA5vu"},"source":["# Challenge 6\n","# ---\n","# Question: Predict the target class given the following dataset.\n","# ---\n","# Dataset url = http://bit.ly/ClassifiedDataset\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]}]}