{"cells":[{"cell_type":"markdown","metadata":{"id":"Bgp1DV4UuWzW"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"8flRWHtSHki3"},"source":["# Python Programming: Bayes Theorem"]},{"cell_type":"markdown","metadata":{"id":"96w9G0XWJrC3"},"source":["<p style=\"color:yellow\">The Bayes Theorem is applicable in machine learning where we get to use a Bayes classifier inorder to make a prediction. In this session, we will learn how to apply this classifer to a few machine learning problems even though later during Core we will spent time exhaustively on working on such problems. While working, we should note that the bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.</p>\n","\n","<p style=\"color:yellow\">For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.</p>\n","\n","<p style=\"color:yellow\">Such classifiers, Naive Bayes classifiers, are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.</p>\n"]},{"cell_type":"markdown","metadata":{"id":"Mhgc8dlkL_UT"},"source":["## Example "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lBLmRc5HgqE"},"outputs":[],"source":["# Example 1\n","# ---\n","# Let's see an overview on how this classifier works, which suitable applications it has, \n","# and how to use it in just a few lines of Python and the Scikit-Learn library.\n","# ---\n","# Question: Build a very simple SPAM detector for SMS messages given the following dataset; \n","# ---\n","# Dataset source = https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n","#"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;html&gt;</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;head&gt;</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&lt;title&gt;UCI Machine Learning Repository: SMS Sp...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&lt;!-- Stylesheet link --&gt;</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               label message\n","0  <!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 ...     NaN\n","1                                             <html>     NaN\n","2                                             <head>     NaN\n","3  <title>UCI Machine Learning Repository: SMS Sp...     NaN\n","4                           <!-- Stylesheet link -->     NaN"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Loading our uploaded Data\n","# ---\n","# We define a separator (in this case, a tab) and rename the columns accordingly\n","# \n","df = pd.read_csv('https://archive.ics.uci.edu/ml/datasets/sms+spam+collection', sep='\\t', header=None, names=['label', 'message'], encoding='utf-8')\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1632323343228,"user":{"displayName":"Eliud Munyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09572496916808459189"},"user_tz":-180},"id":"cgQU75Rhc2i2","outputId":"4e9529c1-948c-4131-dfee-5e7bab9593b6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label message\n","0    NaN     NaN\n","1    NaN     NaN\n","2    NaN     NaN\n","3    NaN     NaN\n","4    NaN     NaN"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Pre-processing\n","# ---\n","# 1. Converting the labels from strings to binary values for our classifier\n","# \n","\n","df['label'] = df.label.map({'ham': 0, 'spam': 1})\n","df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"jG3j0ymwgWOx"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/eliudluda/anaconda3/envs/ds_ml_env/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \"\"\"\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label message\n","0    NaN     NaN\n","1    NaN     NaN\n","2    NaN     NaN\n","3    NaN     NaN\n","4    NaN     NaN"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Pre-processing\n","# ---\n","# 3. Remove any punctuation:\n","# \n","df['message'] = df.message.str.replace('[^\\w\\s]', '')\n","df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"M0B-lfLPgivV"},"outputs":[],"source":["# Pre-processing\n","# ---\n","# 4. tokenize the messages into into single words using nltk. \n","# First, we have to import and download the tokenizer from the console:\n","# \n","# import nltk\n","# nltk.download(\"popular\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ttknwa9guS4"},"outputs":[],"source":["# Pre-processing\n","# ---\n","# 5. Applying the tokenization. \n","# What is tokenization (http://bit.ly/WhatisTokenization)\n","# \n","df['message'] = df['message'].apply(nltk.word_tokenize)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kWxzerKg0V6"},"outputs":[],"source":["# Pre-processing\n","# ---\n","# 6. We then perform some word stemming. \n","# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n","# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n","# \n","from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n"," \n","df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXv3cwwrhAWw"},"outputs":[],"source":["# Pre-processing\n","# ---\n","# 7. We will transform the data into occurrences, \n","# which will be the features that we will feed into our model:\n","#\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# This converts the list of words into space-separated strings\n","df['message'] = df['message'].apply(lambda x: ' '.join(x))\n","\n","count_vect = CountVectorizer()\n","counts = count_vect.fit_transform(df['message'])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VERkaCMThK8I"},"outputs":[],"source":["# Pre-processing\n","# ---\n","# 8. We could leave it as the simple word-count per message, \n","# but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf:\n","#\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","transformer = TfidfTransformer().fit(counts)\n","\n","counts = transformer.transform(counts)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vksf5PobhVQ-"},"outputs":[],"source":["# Training the Model\n","# ---\n","# Now that we have performed feature extraction from our data, \n","# it is time to build our model. We will start by splitting our data into training and test sets:\n","#\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUWlrPzwhfAb"},"outputs":[],"source":["# Training the Model\n","# ---\n","# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n","# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited:\n","# \n","from sklearn.naive_bayes import MultinomialNB\n","\n","model = MultinomialNB().fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DT0zZNSkhpvM"},"outputs":[],"source":["# Evaluating the Model\n","# ---\n","# Once we have put together our classifier, we can evaluate its performance in the testing set:\n","#\n","predicted = model.predict(X_test)\n","\n","print(np.mean(predicted == y_test))\n","\n","# Our simple Naive Bayes Classifier has 94.8% accuracy with this specific test set!"]},{"cell_type":"markdown","metadata":{"id":"5Lgaf8JCiI-L"},"source":["## <font color=\"green\">Challenges</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG5nw1kRtU0g"},"outputs":[],"source":["# Example 1\n","# ---\n","# In this challenge, we have been tasked with creating a classifier, the training set,\n","# then training the classifier using the training set and making a prediction.\n","# ---\n","# The training set (X) consits of length, weight and shoe size. \n","# Y contains the associated labels (male or female).\n","# \n","\n","X = [[121, 80, 44], [180, 70, 43], [166, 60, 38], [153, 54, 37], [166, 65, 40], [190, 90, 47], [175, 64, 39],\n","     [174, 71, 40], [159, 52, 37], [171, 76, 42], [183, 85, 43]]\n","\n","Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male']\n","\n","# Training the classifier:\n","#\n","OUR CODE GOES HERE\n","\n","# Making the prediciton:\n","# Using the GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n","# \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rHn_lBT8iPVY"},"outputs":[],"source":["# Example 2\n","# ---\n","# Question: Use the titanic disaster dataset to create a Gaussian Naive Bayes classifier model \n","# (i.e. from sklearn.naive_bayes import GaussianNB) that will make a prediction of survival \n","# using passenger ticket fare information. \n","# ---\n","# Dataset url: http://bit.ly/TitanicDataset \n","# \n","OUR CODE GOES HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZizDQj7iQ4O"},"outputs":[],"source":["# Example 3\n","# ---\n","# Question: Create a GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n","# to identify the different species of iris flowers.\n","# ---\n","# Dataset url = http://bit.ly/MSIrisDatasetNB\n","# \n","OUR CODE GOES HERE"]}],"metadata":{"colab":{"collapsed_sections":["Mhgc8dlkL_UT","5Lgaf8JCiI-L"],"name":"Copy of Python Programming: Bayes Theorem","provenance":[{"file_id":"17FPHxfGII4DKroTYITFj3r4vAmm0NBYH","timestamp":1632322967525}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
