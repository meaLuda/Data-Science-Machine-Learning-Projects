{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a collection of Python DataScience code snippets \n",
    "\n",
    "### Please feel free to add in your own code snippets and email me a(munyalamea@gmail.com)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ---\n",
    "### ``Requirements and Data loading functions``\n",
    "> ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load files from google drive.....\n",
    "def load_url(url):\n",
    "    url1 = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "    tot_pop__county = pd.read_excel(url1) # can be excel or csv\n",
    "    df = tot_pop__county.copy()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test url\n",
    "import pandas as pd\n",
    "\n",
    "urls_data = {\n",
    "    \"iris_data\":\"http://bit.ly/IrisDataset\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(urls_data['iris_data'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd # I am not sure if this is good code ethic\n",
    "\n",
    "class GetFiles:\n",
    "    \"\"\"\n",
    "        Basically enables you to view every file in a folder.\n",
    "        This is a class to get a list of files either\n",
    "        .csv of .xlsx type\n",
    "         you can the use this in your data science projects\n",
    "         to just get the file by its index\n",
    "\n",
    "        # TODO:\n",
    "            1. Add enumarition for selection only by index\n",
    "            2. Add a read_from_google_Drive feature (tricky but interesting)\n",
    "            3. Add a search by name in folder method (ticky but interesting)\n",
    "            4. View a list of csv/excel files in google drive or an online repositories \n",
    "\n",
    "        #\n",
    "        What I have in mind is basically in the future having something like a cli\n",
    "        where data access is easy by category,size,location,year ranges etc\n",
    "        As of now its just for viewing list of files in a folder and select by index......\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,file_path):\n",
    "        self.f_path = file_path\n",
    "\n",
    "\n",
    "    # this is a dictionary urls of datasets \n",
    "    def datasets(self):\n",
    "\n",
    "        datasets_link =  {\n",
    "            \"Iris_data\": {\n",
    "                \"data\":\"http://bit.ly/IrisDataset\",\n",
    "                },\n",
    "            \"Wine_data\":{\n",
    "                \"data\":\"http://bit.ly/WineDataset\",\n",
    "            },\n",
    "            \"Age_pop_data\":{\n",
    "                \"data\":\"http://bit.ly/AgePopulationDataset\",\n",
    "            },\n",
    "            \"City_ride_dataset\":{\n",
    "                \"data\":\"http://bit.ly/City-RideDataset\",\n",
    "                \"data_description\":[]\n",
    "            },\n",
    "            \"Ride_Dataset\":{\n",
    "                \"data\":\"http://bit.ly/RideDataset\",\n",
    "            },\n",
    "            \"Tea_exports\":{\n",
    "                \"data\":\"http://bit.ly/tea-exports\",\n",
    "            },\n",
    "            \"Kisumu_datasets\": {\n",
    "                \"datasets\": [\n",
    "                    \"http://bit.ly/Kisumu-fish-production\",\n",
    "                    \"http://bit.ly/Kisumu-crop-statistics\",\n",
    "                    \"http://bit.ly/KisumuFoodSecurtyDataset\",\n",
    "                    \"http://bit.ly/Kisumu-fish-production\",\n",
    "                ]\n",
    "            },\n",
    "            \"MedicalCitiesIncome_ds\":{\n",
    "                \"data\":\"http://bit.ly/MedicalCitiesIncomeDataset\"\n",
    "            },\n",
    "            \n",
    "\n",
    "        }\n",
    "    \n",
    "        return datasets_link\n",
    "\n",
    "    # view a list of csv files in a folder\n",
    "    def csv_files(self):\n",
    "        files_dir = [] # path to call that can be run for viewing\n",
    "        for i in glob.glob(f\"{self.f_path}/*.csv\"):\n",
    "            files_dir.append(i)\n",
    "            \n",
    "        file_names = [i.replace(\"/home/eliudluda/Desktop/DataScience/data/\",\"\") for i in files_dir]\n",
    "        \n",
    "        return file_names,files_dir\n",
    "\n",
    "    # view a list of excel files\n",
    "    def excel_files(self):\n",
    "        files_dir = []\n",
    "        print(file_names)\n",
    "        for i in glob.glob(f\"{self.f_path}/*.xlsx\"):\n",
    "            files_dir.append(i)\n",
    "            \n",
    "        file_names = [i.replace(\"/home/eliudluda/Desktop/DataScience/data/\",\"\") for i in files_dir]\n",
    "\n",
    "        return file_names,files_dir\n",
    "    \n",
    "    # load data from a google drive \n",
    "    def load_from_drive(self):\n",
    "        \"\"\"\n",
    "            Ensure you have imported pandas\n",
    "        \"\"\"\n",
    "        url1 = 'https://drive.google.com/uc?id=' + self.f_path.split('/')[-2]\n",
    "        tot_pop__county = pd.read_excel(url1) # can be excel or csv\n",
    "        df = tot_pop__county.copy()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Population_by_state.csv', 'uni_admission.csv', 'Interpol.csv', 'government_appointments.csv', 'marathon_results_2016.csv', 'households-paying-for-the-water-they-use-in-kenya-1.csv', 'HIV_Prevention_Adolescents_2021.csv', 'GrandElectors_by_state.csv', 'Countries-exercise.csv', 'Transactions.csv', 'results.csv', 'Glass.csv', 'energy_mining_dataset.csv', 'File Name.csv', 'urban_centres_dataset.csv', 'Cities.csv', 'tea_production.csv', 'Percentage_Distribution_of_Population_by_type_of_Disability_County_Estimates2005_6.csv', 'train.csv', 'DF_Rolling_Stdev.csv', 'visitors_to_kenya.csv', 'households_dataset.csv', 'DF_Raw_Data.csv', 'Countries.csv', 'winequality-red.csv', 'test.csv', 'position_salaries.csv', 'bus_travels.csv', 'kewi-water-test-and-results-csv-1.csv', 'spambase.csv', 'busia-county-waterborn-diseases-jan-2019-to-april-2020..xlsx-sheet3.csv', '2009_Census_Volume_II_Table_5_Households_by_main_type_of_Roofing_Material_for_the_main_dwelling_unit_by_district.csv', 'Rural_Urban_Population_By_Age_Sex_and_by_District__2009.csv', 'cells_geo.csv', 'lighting_dataset.csv', 'percentage-of-population-with-access-to-improved-water-facilities-in-kenya-1.csv', 'student_exam_data.csv', 'covid_caner_poland.csv', 'world_countries.csv', 'world_cities.csv', 'Uganda_Karamoja_Subcounty_Crop_Yield_Population.csv', 'population_by_district.csv', 'fifa_ranking.csv', 'government_project_summary.csv', '3.01. Country clusters.csv', 'Gender_heights.csv']\n"
     ]
    }
   ],
   "source": [
    "data_file_path = \"/home/eliudluda/Desktop/DataScience/data\" # where your data sets are stored\n",
    "\n",
    "\n",
    "try:\n",
    "    f_names,f_path = GetFiles(data_file_path).csv_files()\n",
    "except:\n",
    "    print(\"Check file path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 File name: Population_by_state.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Population_by_state.csv\n",
      "\n",
      "1 File name: uni_admission.csv \t File path: /home/eliudluda/Desktop/DataScience/data/uni_admission.csv\n",
      "\n",
      "2 File name: Interpol.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Interpol.csv\n",
      "\n",
      "3 File name: government_appointments.csv \t File path: /home/eliudluda/Desktop/DataScience/data/government_appointments.csv\n",
      "\n",
      "4 File name: marathon_results_2016.csv \t File path: /home/eliudluda/Desktop/DataScience/data/marathon_results_2016.csv\n",
      "\n",
      "5 File name: households-paying-for-the-water-they-use-in-kenya-1.csv \t File path: /home/eliudluda/Desktop/DataScience/data/households-paying-for-the-water-they-use-in-kenya-1.csv\n",
      "\n",
      "6 File name: HIV_Prevention_Adolescents_2021.csv \t File path: /home/eliudluda/Desktop/DataScience/data/HIV_Prevention_Adolescents_2021.csv\n",
      "\n",
      "7 File name: GrandElectors_by_state.csv \t File path: /home/eliudluda/Desktop/DataScience/data/GrandElectors_by_state.csv\n",
      "\n",
      "8 File name: Countries-exercise.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Countries-exercise.csv\n",
      "\n",
      "9 File name: Transactions.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Transactions.csv\n",
      "\n",
      "10 File name: results.csv \t File path: /home/eliudluda/Desktop/DataScience/data/results.csv\n",
      "\n",
      "11 File name: Glass.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Glass.csv\n",
      "\n",
      "12 File name: energy_mining_dataset.csv \t File path: /home/eliudluda/Desktop/DataScience/data/energy_mining_dataset.csv\n",
      "\n",
      "13 File name: File Name.csv \t File path: /home/eliudluda/Desktop/DataScience/data/File Name.csv\n",
      "\n",
      "14 File name: urban_centres_dataset.csv \t File path: /home/eliudluda/Desktop/DataScience/data/urban_centres_dataset.csv\n",
      "\n",
      "15 File name: Cities.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Cities.csv\n",
      "\n",
      "16 File name: tea_production.csv \t File path: /home/eliudluda/Desktop/DataScience/data/tea_production.csv\n",
      "\n",
      "17 File name: Percentage_Distribution_of_Population_by_type_of_Disability_County_Estimates2005_6.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Percentage_Distribution_of_Population_by_type_of_Disability_County_Estimates2005_6.csv\n",
      "\n",
      "18 File name: train.csv \t File path: /home/eliudluda/Desktop/DataScience/data/train.csv\n",
      "\n",
      "19 File name: DF_Rolling_Stdev.csv \t File path: /home/eliudluda/Desktop/DataScience/data/DF_Rolling_Stdev.csv\n",
      "\n",
      "20 File name: visitors_to_kenya.csv \t File path: /home/eliudluda/Desktop/DataScience/data/visitors_to_kenya.csv\n",
      "\n",
      "21 File name: households_dataset.csv \t File path: /home/eliudluda/Desktop/DataScience/data/households_dataset.csv\n",
      "\n",
      "22 File name: DF_Raw_Data.csv \t File path: /home/eliudluda/Desktop/DataScience/data/DF_Raw_Data.csv\n",
      "\n",
      "23 File name: Countries.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Countries.csv\n",
      "\n",
      "24 File name: winequality-red.csv \t File path: /home/eliudluda/Desktop/DataScience/data/winequality-red.csv\n",
      "\n",
      "25 File name: test.csv \t File path: /home/eliudluda/Desktop/DataScience/data/test.csv\n",
      "\n",
      "26 File name: position_salaries.csv \t File path: /home/eliudluda/Desktop/DataScience/data/position_salaries.csv\n",
      "\n",
      "27 File name: bus_travels.csv \t File path: /home/eliudluda/Desktop/DataScience/data/bus_travels.csv\n",
      "\n",
      "28 File name: kewi-water-test-and-results-csv-1.csv \t File path: /home/eliudluda/Desktop/DataScience/data/kewi-water-test-and-results-csv-1.csv\n",
      "\n",
      "29 File name: spambase.csv \t File path: /home/eliudluda/Desktop/DataScience/data/spambase.csv\n",
      "\n",
      "30 File name: busia-county-waterborn-diseases-jan-2019-to-april-2020..xlsx-sheet3.csv \t File path: /home/eliudluda/Desktop/DataScience/data/busia-county-waterborn-diseases-jan-2019-to-april-2020..xlsx-sheet3.csv\n",
      "\n",
      "31 File name: 2009_Census_Volume_II_Table_5_Households_by_main_type_of_Roofing_Material_for_the_main_dwelling_unit_by_district.csv \t File path: /home/eliudluda/Desktop/DataScience/data/2009_Census_Volume_II_Table_5_Households_by_main_type_of_Roofing_Material_for_the_main_dwelling_unit_by_district.csv\n",
      "\n",
      "32 File name: Rural_Urban_Population_By_Age_Sex_and_by_District__2009.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Rural_Urban_Population_By_Age_Sex_and_by_District__2009.csv\n",
      "\n",
      "33 File name: cells_geo.csv \t File path: /home/eliudluda/Desktop/DataScience/data/cells_geo.csv\n",
      "\n",
      "34 File name: lighting_dataset.csv \t File path: /home/eliudluda/Desktop/DataScience/data/lighting_dataset.csv\n",
      "\n",
      "35 File name: percentage-of-population-with-access-to-improved-water-facilities-in-kenya-1.csv \t File path: /home/eliudluda/Desktop/DataScience/data/percentage-of-population-with-access-to-improved-water-facilities-in-kenya-1.csv\n",
      "\n",
      "36 File name: student_exam_data.csv \t File path: /home/eliudluda/Desktop/DataScience/data/student_exam_data.csv\n",
      "\n",
      "37 File name: covid_caner_poland.csv \t File path: /home/eliudluda/Desktop/DataScience/data/covid_caner_poland.csv\n",
      "\n",
      "38 File name: world_countries.csv \t File path: /home/eliudluda/Desktop/DataScience/data/world_countries.csv\n",
      "\n",
      "39 File name: world_cities.csv \t File path: /home/eliudluda/Desktop/DataScience/data/world_cities.csv\n",
      "\n",
      "40 File name: Uganda_Karamoja_Subcounty_Crop_Yield_Population.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Uganda_Karamoja_Subcounty_Crop_Yield_Population.csv\n",
      "\n",
      "41 File name: population_by_district.csv \t File path: /home/eliudluda/Desktop/DataScience/data/population_by_district.csv\n",
      "\n",
      "42 File name: fifa_ranking.csv \t File path: /home/eliudluda/Desktop/DataScience/data/fifa_ranking.csv\n",
      "\n",
      "43 File name: government_project_summary.csv \t File path: /home/eliudluda/Desktop/DataScience/data/government_project_summary.csv\n",
      "\n",
      "44 File name: 3.01. Country clusters.csv \t File path: /home/eliudluda/Desktop/DataScience/data/3.01. Country clusters.csv\n",
      "\n",
      "45 File name: Gender_heights.csv \t File path: /home/eliudluda/Desktop/DataScience/data/Gender_heights.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,(a,b) in enumerate(zip(f_names,f_path)):\n",
    "    print(f\"{index} File name: {a} \\t File path: {b}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">---\n",
    "### ``Data Cleaning Code snippets``\n",
    ">---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to round off values in both columns to remove the decimals\n",
    "def rounding(data,col):\n",
    "  data[col]=data[col].apply(np.ceil)\n",
    "  return data[col].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes outliers in particular columns\n",
    "def Remove_Outlier(Df, col_name):\n",
    "    q1 = Df[col_name].quantile(0.25)\n",
    "    q3 = Df[col_name].quantile(0.75)\n",
    "\n",
    "    iqr = q3-q1  # Interquartile range\n",
    "\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    \n",
    "    df_out = Df.loc[(Df[col_name] > lower_bound) & (Df[col_name] < upper_bound)]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">---\n",
    "\n",
    "### Visualization code snippets\n",
    "\n",
    ">---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering values in seaborn countplot\n",
    "#plt.figure(figsize=(15, 10))\n",
    "#sns.countplot(US_news['subject'], order=US_news['subject'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization for bivariate analysis\n",
    "def bivariate_viz(data, variable_1, variable_2, palette):\n",
    "    data = data.nunique\n",
    "    bi_data = data.groupby([variable_1, variable_2])[variable_2].count()\n",
    "    output = pd.DataFrame(bi_data)\n",
    "    df = output.rename(columns={f\"{variable_2}\": 'Count'}).reset_index()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax, bar = plt.subplots(figsize=(12, 10))\n",
    "    ax = sns.barplot(x=f\"{variable_1}\", y='Count',\n",
    "                     hue=f\"{variable_2}\", data=df, palette=palette)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_variate(data, column, plot_type, palette):\n",
    "\n",
    "    # value counts\n",
    "    ValueCounts = data[column].value_counts()\n",
    "\n",
    "    print()\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # determining the plot\n",
    "    if plot_type == \"bar\":\n",
    "\n",
    "        # bar chart\n",
    "        bar, ax = plt.subplots(figsize=(12, 10))\n",
    "        ax = sns.barplot(x=ValueCounts.index,\n",
    "                         y=ValueCounts.values, data=data, palette='cool')\n",
    "        ax.set_ylabel(\"Count\", fontsize=18)\n",
    "        ax.set_xlabel(f\"{column.title()}\", fontsize=18)\n",
    "        ax.set_title(f\"Distribution of {column.title()}\", fontsize=22)\n",
    "        bar.savefig(f\"{column}.png\")\n",
    "\n",
    "    elif plot_type == \"displot\":\n",
    "        bar, ax = plt.subplots(figsize=(12, 10))\n",
    "        ax = sns.displot(data, x=column, bins=13)\n",
    "        ax.set_xlabel(f\"{column.title()}\", fontsize=18)\n",
    "        ax.set_title(f\"Distribution of {column.title()}\", fontsize=22)\n",
    "        bar.savefig(f\"{column}.png\")\n",
    "\n",
    "    return ValueCounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">---\n",
    "\n",
    "### Machine Learning code snippets\n",
    "\n",
    ">---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to classify and regress then output answer\n",
    "class reg_and_clsf:\n",
    "    def __init__(self, X, X_train, X_test, y_train, y_test):\n",
    "        self.X = X\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def clasy_ada(self):\n",
    "        # # Create a decision tree classifier\n",
    "        tree = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "        # Ada boost instance\n",
    "        ada = AdaBoostRegressor(random_state=96, base_estimator=RandomForestRegressor(\n",
    "            random_state=101), n_estimators=100, learning_rate=0.01)\n",
    "\n",
    "        # train model\n",
    "        ada.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # get score on training data\n",
    "        score_train = ada.score(self.X_train, self.y_train)\n",
    "\n",
    "        # get score on test data\n",
    "        score_test = ada.score(self.X_test, self.y_test)\n",
    "\n",
    "        test = pd.DataFrame({\n",
    "            \"Train_Score\": [score_train],\n",
    "            \"Test_Score\": [score_test],\n",
    "        })\n",
    "\n",
    "        return test\n",
    "\n",
    "    def classy_rand_frst(self):\n",
    "        forest = RandomForestRegressor(\n",
    "            n_estimators=100, random_state=42, min_samples_split=20, max_depth=5)\n",
    "        forest = forest.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Predict based on the model we've trained\n",
    "        y_pred = forest.predict(self.X_test)\n",
    "\n",
    "        comparison_frame = pd.DataFrame(\n",
    "            {'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "\n",
    "        rand_frst_metrics = pd.DataFrame(\n",
    "            {'Mean Absolute Error:': [metrics.mean_absolute_error(self.y_test, y_pred)],\n",
    "                'Mean Squared Error:': [metrics.mean_squared_error(self.y_test, y_pred)],\n",
    "                'Root Mean Squared Error:': [np.sqrt(metrics.mean_squared_error(self.y_test, y_pred))]\n",
    "             }\n",
    "        )\n",
    "\n",
    "        return comparison_frame, rand_frst_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to do categorisation ---unfinished********\n",
    "def decision_boundary(X, y, model, res, test_idx=None):\n",
    "    markers = ['s', 'o', 'x']\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    colormap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    x_min, x_max = X[:, 0].min()-1, X[:, 0].max()+1\n",
    "    y_min, y_max = X[:, 1].min()-1, X[:, 1].max()+1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, res),\n",
    "                         np.arange(y_min, y_max, res))\n",
    "    z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    zz = z.reshape(xx.shape)\n",
    "    plt.pcolormesh(xx, yy, zz, cmap=colormap)\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(X[y == cl, 0], X[y == cl, 1], c=colors[idx], cmap=plt.cm.Paired,\n",
    "                    edgecolors='k', marker=markers[idx], label=cl, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A class to classify and regress then output answer\n",
    "class Home:\n",
    "    # Load data\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        '''\n",
    "            Load your X_train, X_test, y_train, y_test\n",
    "        '''\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    # Scale my data\n",
    "    def scale_df(self):\n",
    "        \"\"\"\n",
    "            This function scales our x train and test sets\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)\n",
    "\n",
    "        X_train = scaler.transform(self.X_train)\n",
    "        X_test = scaler.transform(self.X_test)\n",
    "\n",
    "        return X_train, X_test\n",
    "\n",
    "    # KNN\n",
    "    def knn_cls(self, k_value):\n",
    "        '''\n",
    "            Input K value\n",
    "        '''\n",
    "        X_train, X_test = self.scale_df()\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k_value)\n",
    "        classifier.fit(X_train, self.y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        from sklearn.metrics import classification_report, confusion_matrix\n",
    "        print(\"\\n\\t=================================== Confusion Matrix ====================================\\n\")\n",
    "        print(confusion_matrix(self.y_test, y_pred))\n",
    "\n",
    "        print(\"\\n\\t=================================== Classification Report ====================================\\n\")\n",
    "\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def k_val_disp(self):\n",
    "\n",
    "        X_train, X_test = self.scale_df()\n",
    "        neighbors = np.arange(1, 9)\n",
    "        train_accuracy = np.empty(len(neighbors))\n",
    "        test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "        # Loop over different values of k\n",
    "        for i, k in enumerate(neighbors):\n",
    "            # Setup a k-NN Classifier with k neighbors: knn\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            # Fit the classifier to the training data\n",
    "            knn.fit(X_train, self.y_train)\n",
    "            # Compute accuracy on the training set\n",
    "            train_accuracy[i] = knn.score(X_train, self.y_train)\n",
    "            # Compute accuracy on the testing set\n",
    "            test_accuracy[i] = knn.score(X_test, self.y_test)\n",
    "        # Generate plot\n",
    "        plt.title('k-NN: Varying Number of Neighbors')\n",
    "        plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "        plt.plot(neighbors, train_accuracy, label='Training Accuracy')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Number of Neighbors')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    # Naive Bayes\n",
    "\n",
    "    def naive_b(self):\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "        X_train, X_test = self.scale_df()\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, self.y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        check = pd.DataFrame(\n",
    "            {\n",
    "                \"Actual\": self.y_test.flatten(),\n",
    "                \"Predicted\": y_pred.flatten(),\n",
    "            }\n",
    "        )\n",
    "        return check\n",
    "\n",
    "    def check_naive(self,):\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "        X_train, X_test = self.scale_df()\n",
    "        classifier = GaussianNB()\n",
    "        # Predicting the Test set results\n",
    "        classifier.fit(X_train, self.y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        acc_s = accuracy_score(self.y_test, y_pred)\n",
    "        conf_m = confusion_matrix(self.y_test, y_pred)\n",
    "\n",
    "        return acc_s, conf_m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Exports data to a csv file\n",
    "def export(data, name):\n",
    "    file_name = name+\".csv\"\n",
    "\n",
    "    return data.to_csv(file_name, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e6cad420e4398edbb7ba2374d625154d5929472e7c7049b665a8784c474571"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ds_ml_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
